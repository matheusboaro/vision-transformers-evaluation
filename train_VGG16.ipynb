{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","collapsed_sections":["oDaKJgxzP9Fu"],"mount_file_id":"1ZFd89HgReXyclb55ggqxT901B_dLxEP4","authorship_tag":"ABX9TyOB0+1Y4ixHTotHPPgCacnf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Imports and installations\n","- Pytorch\n","- Database import directly from Kaggle\n","\n","Data source: https://www.kaggle.com/xhlulu/140k-real-and-fake-faces"],"metadata":{"id":"i43SALPyP30W"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ti0cOXYIqglA"},"outputs":[],"source":["!pip install timm\n","!pip install kaggle\n","! mkdir ~/.kaggle}\n","!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json\n","! chmod 600 ~/.kaggle/kaggle.json\n"]},{"cell_type":"code","source":["! kaggle datasets download xhlulu/140k-real-and-fake-faces\n","! unzip '140k-real-and-fake-faces.zip';"],"metadata":{"id":"S0BTWUFCqtPG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from json import load\n","import torch\n","import numpy as np\n","from torchvision.datasets import ImageFolder\n","from torchvision.transforms import ToTensor,Compose, Resize, Normalize\n","from torch.utils.data.dataloader import DataLoader\n","from torch.utils.data import random_split\n","#from vision_transformer import VisionTransformer\n","from torch import nn\n","import timm\n","import torch.nn.functional as F"],"metadata":{"id":"Z-t00ByAq54v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Early Stopping\n","Implements the early stopping technique based on the value of the loss function. Used to prevent the training set from overfitting.\n","\n","Source: https://github.com/Bjarten/early-stopping-pytorch\n"],"metadata":{"id":"oDaKJgxzP9Fu"}},{"cell_type":"code","source":["class EarlyStopping:\n","    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n","    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n","        \"\"\"\n","        Args:\n","            patience (int): How long to wait after last time validation loss improved.\n","                            Default: 7\n","            verbose (bool): If True, prints a message for each validation loss improvement. \n","                            Default: False\n","            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n","                            Default: 0\n","            path (str): Path for the checkpoint to be saved to.\n","                            Default: 'checkpoint.pt'\n","            trace_func (function): trace print function.\n","                            Default: print            \n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","        self.trace_func = trace_func\n","    def __call__(self, val_loss, model):\n","\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''Saves model when validation loss decrease.'''\n","        if self.verbose:\n","            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), self.path)\n","        self.val_loss_min = val_loss"],"metadata":{"id":"7vKeMY0G3dxx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Auxiliary functions\n","- load_data : Loads the training, testing and validation set.\n","- acurracy : Calculates the accuracy of a set of logits.\n","- validation_on_end : Calculates the values of loss and acuracy per epoch and averages these values per batch.\n","- epoch_end: Prints the metrics during training, after each epoch.\n","- get_default_device: Identifies the GPU devices present in the environment.\n"],"metadata":{"id":"CoNT1B1dQYDk"}},{"cell_type":"code","source":["def load_data(path,train_rate,batch_size,test=False):\n","    NORMALIZE_MEAN = (0.5, 0.5, 0.5)\n","    NORMALIZE_STD = (0.5, 0.5, 0.5)\n","    transform = Compose([\n","              Resize(size=(224, 224)),\n","              ToTensor(),\n","              Normalize(NORMALIZE_MEAN, NORMALIZE_STD),\n","              ])\n","    \n","    dataset_train = ImageFolder(path+\"/train\", transform=transform)\n","    dataset_test = ImageFolder(path+\"/test\", transform=transform)\n","    dataset_valid =ImageFolder(path+\"/valid\", transform=transform)\n","\n","    train_dl = DataLoader(dataset_train,batch_size,shuffle=True)\n","    test_dl = DataLoader(dataset_test,batch_size)\n","    valid_dl = DataLoader(dataset_valid,batch_size)\n","    \n","    return train_dl,test_dl,valid_dl\n","\n","def accuracy(outputs, labels):\n","    _,preds = torch.max(outputs,dim = 1)\n","    return torch.tensor(torch.sum(preds==labels).item() / len(preds))\n","def validation_epoch_end(outputs):\n","        batch_loss = [x['val_loss'] for x in outputs]\n","        epoch_loss = torch.stack(batch_loss).mean()\n","        batch_acc = [x['val_acc'] for x in outputs]\n","        epoch_acc = torch.stack(batch_acc).mean()\n","\n","        return {\"val_loss\":epoch_loss.item(),'val_acc':epoch_acc.item()}\n","def epoch_end( epoch, result):\n","        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n","            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"],"metadata":{"id":"PUWM-88qrrNz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_default_device():\n","\n","    if torch.cuda.is_available():\n","        return torch.device(\"cuda\")\n","    else:\n","        return torch.device(\"cpu\")\n","\n","def to_device(data,device):\n","    if isinstance(data, (list,tuple)):\n","        return [to_device(x,device) for x in data]\n","\n","    return data.to(device, non_blocking=True)\n","\n","class DeviceDataLoader():\n","\n","    def __init__(self,dl,device):\n","        self.dl = dl\n","        self.device = device\n","\n","    def __iter__(self):\n","        for b in self.dl:\n","            yield to_device(b,self.device)\n","\n","    def __len__(self):\n","        return len(self.dl)"],"metadata":{"id":"sc0mPfZWrzS3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Trainning\n"],"metadata":{"id":"u3vOC4KaRdqh"}},{"cell_type":"markdown","source":["## Model Loading\n","- VGG16\n","\n","Source:\n","https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/vgg.py"],"metadata":{"id":"ekM1ah8lRJXB"}},{"cell_type":"code","source":["\n","model_name = 'vgg16'\n","model= timm.create_model(model_name, pretrained=True,num_classes=2)\n","\n","model\n","\n"],"metadata":{"id":"RfuW8Y3xr1rD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training and Evaluation Functions\n","- evaluate: Evaluates the model with the validation set\n","- fit: trains the model for a specified number of epochs."],"metadata":{"id":"zRpjWw21Rakv"}},{"cell_type":"code","source":["@torch.no_grad()\n","def evaluate(model, val_loader):\n","    outputs =[]\n","    for batch in val_loader:\n","        out = model(batch[0])\n","        loss = F.cross_entropy(out,batch[1])\n","        acc = accuracy(out,batch[1])\n","        outputs.append({'val_loss': loss.detach(), \"val_acc\":acc})\n","    return validation_epoch_end(outputs)\n","        \n","\n","\n","def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD,path_to_save):\n","    history = []\n","    optimizer = opt_func(model.parameters(),lr)\n","    early_stopping = EarlyStopping(patience=4, verbose=True, path=path_to_save)\n","    for epoch in range(epochs):\n","        model.train()\n","        train_losses = []\n","        total = len(train_loader)\n","        for batch in train_loader:\n","            out = model(batch[0])\n","            loss = F.cross_entropy(out,batch[1])\n","            train_losses.append(loss)\n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        result = evaluate(model, val_loader)\n","        result['train_loss'] = torch.stack(train_losses).mean().item()\n","        epoch_end(epoch,result)\n","        early_stopping(result['val_loss'], model)\n","        \n","        if early_stopping.early_stop:\n","            print(\"Early stopping\")\n","            break\n","        history.append(result)\n","\n","    return history"],"metadata":{"id":"caCBHRiEryCg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Main Script\n","- Database loading\n","- Transferring the model and the training and validation sets to the GPU\n","- Training the model"],"metadata":{"id":"2K_oSyiGSBZX"}},{"cell_type":"code","source":["train,test,valid = load_data('/content/real_vs_fake/real-vs-fake',0.8,128)\n","device = get_default_device()\n","\n","train = DeviceDataLoader(train,device)\n","valid = DeviceDataLoader(valid,device)\n","model.to(device);"],"metadata":{"id":"peXI4t5Xr-P0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_epochs = 50\n","opt_func = torch.optim.Adam\n","lr = 0.001\n","save_path = ''\n","history = fit(num_epochs, lr, model,train,valid, opt_func,save_path)"],"metadata":{"id":"mszw9MWEsL5N"},"execution_count":null,"outputs":[]}]}